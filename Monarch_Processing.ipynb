{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8248fa9b-b5bb-4e7d-a45d-a99213e038db",
   "metadata": {},
   "source": [
    "# Monarch Data Processing Notebook\n",
    "## Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ef052-9416-4e79-824e-b1df442f85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from anyio import get_cancelled_exc_class\n",
    "from monarchmoney import MonarchMoney\n",
    "mm = MonarchMoney()\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import datetime\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26edfe8e-6f4a-4b1b-9d03-5d61a3617b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Monarch Money session token.  If it doesn't exist, prompt the user to login\n",
    "\n",
    "try:\n",
    "    mm.load_session(filename=\"/data/mm_session.pickle\")\n",
    "    print(\"Monarch session has been loaded successfully\")\n",
    "except FileNotFoundError as e:\n",
    "    # Session not found, login on the console.\n",
    "    print(\"A console should appear.  In the console, enter \\\"await mm.interactive_login()\\\" then rerun the notebook.\")\n",
    "    %qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e517cb9-964c-4f02-940c-069024ed7dfd",
   "metadata": {},
   "source": [
    "## Define key constants\n",
    "Change these values to specify:\n",
    "* Date range of transactions to download\n",
    "* List of tags to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9190c70-77f3-44b3-b1b6-11fb7c8754b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the start and end dates (inclusive) in YYYY, MM, DD format\n",
    "# Dates must be at least 3 days apart\n",
    "startDate = datetime.datetime(2023, 1, 1)\n",
    "endDate   = datetime.datetime(2024, 12, 31)\n",
    "\n",
    "excludeTagsList = ['Wedding']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f46b8cf-599b-4284-974a-0ed96e21cfac",
   "metadata": {},
   "source": [
    "## Get the data from Monarch\n",
    "This cell downloads all the transactions for the specified dates (inclusive).\n",
    "If there are too many transactions, the request will time out, so this cell will recursively divide the date range until the number of transactions can successfully be downloaded within the time limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b41ac-da95-4419-9d36-21927c2d91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the trancactions from startDate to endDate\n",
    "# This approach allows you to get transactions for arbitrary date ranges\n",
    "# while avoiding TimeoutErrors\n",
    "\n",
    "\n",
    "# Assumption: startDate and endDate are >3 days apart at a minimum\n",
    "#\n",
    "# Params:\n",
    "#   transactions - dataframe of aggregate transactions\n",
    "#   startDate    - datetime object of the start date\n",
    "#   endDate      - datetime object of the end date\n",
    "# Returns:\n",
    "#   dataframe of aggregate transaction data\n",
    "async def getTransactions(transactions, startDate, endDate):\n",
    "    # Check if the dates are within 2 days.  If the API calls are failing enough to reduce the window\n",
    "    # to 2 days, something is likely very wrong.\n",
    "    if ((endDate - startDate <= datetime.timedelta(days=2))):\n",
    "        print(\"Unable to successfully obtain transaction data\")\n",
    "        raise UserWarning(\"Program Error\")\n",
    "    \n",
    "    # Try to get the transaction data\n",
    "    try:\n",
    "        t = await mm.get_transactions(limit = 5000, \n",
    "                                      start_date = startDate.strftime('%Y-%m-%d'), \n",
    "                                      end_date = endDate.strftime('%Y-%m-%d'))\n",
    "        return pd.concat([ transactions, pd.DataFrame(t['allTransactions']['results']) ])\n",
    "    except (get_cancelled_exc_class(), TimeoutError) as e:\n",
    "        # If we get here it's because of a timeout error, likely due to there being too many transactions to download.\n",
    "        # Since the upstream libraries don't offer a method to increase the timeout period, our workaround is to batch the\n",
    "        # API calls to request a smaller number of transactions in each call.  Recurse until we have success.\n",
    "        delta = datetime.timedelta( ((endDate - startDate) / 2).days)\n",
    "        t1_end = (endDate - delta - datetime.timedelta(seconds=1))\n",
    "        t2_start = t1_end + datetime.timedelta(days=1)\n",
    "        print(\"Timeout, trying \" + startDate.strftime('%Y-%m-%d') + \" to \" + t1_end.strftime('%Y-%m-%d') + \n",
    "              \" and \" + t2_start.strftime('%Y-%m-%d') + \" to \" + endDate.strftime('%Y-%m-%d'))\n",
    "        t1 = await getTransactions(transactions, startDate, t1_end)\n",
    "        t2 = await getTransactions(transactions, t2_start, endDate)\n",
    "        return pd.concat([ transactions, t1, t2 ])\n",
    "    except KeyError as e:\n",
    "        print(t)\n",
    "        raise(e)\n",
    "\n",
    "# End of function definition\n",
    "        \n",
    "# Create an empty dataframe to hold the transaction data\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "# Call the above function\n",
    "df_raw = await getTransactions(df_raw, startDate, endDate)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8bb2ff-bc8f-4f12-ad2f-5024387d1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data to a new variable so we can re-run the data processing without querying the API again.\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2a920-618c-4542-95bc-8e1433b5a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many transactions do we have?\n",
    "print(\"Dataframe contains \" + str(len(df)) + \" transactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a3b85-91bd-4b55-af64-9dccdc7998d9",
   "metadata": {},
   "source": [
    "## Massage the data into formats ready for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963e2f5-1784-4312-b02c-f02f4dc82e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index and sort by date\n",
    "df = df.sort_values('date', ignore_index=True).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5cef4-68f2-481a-ae84-72cd94d8433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull some key info to the top level of the dataframe\n",
    "\n",
    "df['accountName']  = df['account'].apply( lambda x: x.get('displayName') )\n",
    "df['merchantName'] = df['merchant'].apply( lambda x: x.get('name') )\n",
    "df['categoryName'] = df['category'].apply( lambda x: x.get('name') )\n",
    "\n",
    "tag_list = []\n",
    "for x in df['tags']:\n",
    "    tgs = \"\"\n",
    "    for y in x:\n",
    "        tgs += y['name'] + \",\"\n",
    "    tag_list.append(tgs)\n",
    "\n",
    "df['Tags'] = tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1a62b-7313-4dd0-9689-ae9a07ee846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataFrame keys\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bdee96-61ea-426e-a2dc-7919daa810a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(df))\n",
    "#print(len(df[df.date > '2024-02-02']))\n",
    "df['Date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431fff5-9e6b-4040-bc9b-6087617e2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns\n",
    "# The ones with the data we need are now the Capitalized variants\n",
    "dfc = df.drop(columns=['date','category','merchant','tags','account'])\n",
    "\n",
    "# Define the month resample function\n",
    "def resample(group):\n",
    "    return group.resample('ME', on='Date').agg({'amount':'sum', 'Date':'last'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6657e2c-0996-4cd8-8afd-515ab848f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process transactions tagged for exclusion\n",
    "print(\"Transactions matching exclusion criteria: \" + str(len(dfc[dfc.Tags.str.contains('|'.join(excludeTagsList))])))\n",
    "# Perform the removal\n",
    "dfc = dfc[~(dfc.Tags.str.contains('|'.join(excludeTagsList)))]\n",
    "\n",
    "# Remove any transaction marked for exclusion from reports\n",
    "dfg = dfc[(dfc.hideFromReports == False)]\n",
    "\n",
    "# The following line inverts the balances to show expenses as positive numbers\n",
    "# and refunds as negative numbers.\n",
    "dfg.loc[:, 'amount'] = dfg.loc[:, 'amount'].apply(lambda x: -x).copy()\n",
    "\n",
    "# Resample the dataframe into months.  Each month will have each category, which contains the sum of applicable transaction amounts\n",
    "dfg = dfg.groupby('categoryName').apply(resample, include_groups=False).swaplevel()\n",
    "\n",
    "# After the resampling, the 'Date' column is now garbage data so lets drop that column.\n",
    "# The date info that we care about is now part of the index for the dataframe\n",
    "dfg = dfg.drop(columns=['Date'])\n",
    "\n",
    "dfg = dfg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080f5cf-3076-48be-b063-739f68b6f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove neutral categories which aren't true expenses\n",
    "dfg = dfg[~(dfg.categoryName.isin(['Transfer', 'Buy', 'Sell', 'Credit Card Payment']))]\n",
    "# Remove income categories\n",
    "dfg = dfg[~(dfg.categoryName.isin(['Paychecks', 'Other Income', 'Dividends & Capital Gains', 'Interest']))]\n",
    "# Pivot the dataframe to organize the data by category per month\n",
    "pivot2 = pd.pivot_table(data=dfg, index=['Date'], columns=['categoryName'], values='amount')\n",
    "\n",
    "\n",
    "# pivot3 keeps the top N categories and groups the rest into 'Other'\n",
    "numCategories = 10\n",
    "other_list = list(set(pivot2.keys()) - set(pivot2.sum().sort_values(ascending=False)[:numCategories].keys()) )\n",
    "\n",
    "pivot3 = pivot2.copy()\n",
    "pivot3['Other'] = pivot2[other_list].sum(axis=1)\n",
    "pivot3 = pivot3.drop(columns=other_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d33661-73f2-4e7d-a465-a2b7b12a7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the dataframe to organize the data by total spend per month\n",
    "pivotTotal = pd.pivot_table(data=dfg, index=['Date'], columns=['categoryName'], values='amount').copy().sum(axis=1).reset_index()\n",
    "pivotTotal['Date'] -= datetime.timedelta(days=30)\n",
    "pivotTotal = pivotTotal.set_index('Date')\n",
    "pivotTotal.rename(columns={0:'Monthly Spend'}, inplace=True)\n",
    "\n",
    "# Display the plot\n",
    "fig = px.bar(pivotTotal, height=600, width=1000, template=\"plotly_dark\")\n",
    "# Uncomment line below for light mode instead\n",
    "# fig = px.bar(pivot4, height=600, width=1000)\n",
    "#pio.renderers.default = 'jupyterlab'\n",
    "fig.show(renderer=\"iframe\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2cdd8-b9cf-474c-b27a-39dc4b4e0c23",
   "metadata": {},
   "source": [
    "##  Plot Monthly Spending Over Specified Time Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c986553-e496-4bef-b521-94782544e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this with Plotly Express\n",
    "\n",
    "# Shift the date because otherwise each month is off-by-one\n",
    "pivot4 = pivot3.reset_index()\n",
    "pivot4['Date'] -= datetime.timedelta(days=30)\n",
    "pivot4 = pivot4.set_index('Date')\n",
    "\n",
    "# Display the plot\n",
    "fig = px.bar(pivot4, height=600, width=1000, template=\"plotly_dark\")\n",
    "# Uncomment line below for light mode instead\n",
    "# fig = px.bar(pivot4, height=600, width=1000)\n",
    "#pio.renderers.default = 'jupyterlab'\n",
    "fig.show(renderer=\"iframe\")\n",
    "#pio.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043c8d4-0f5d-4ce1-96b9-f5bf25b9a8c5",
   "metadata": {},
   "source": [
    "## Other Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41b7e9-ca17-4fc7-a293-378de069a076",
   "metadata": {},
   "source": [
    "### Example: Review monthly spending averages before and after a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7dfec-bdda-4771-979c-5ba68997a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot5 = pd.pivot_table(data=dfg, index=['Date'], values='amount', aggfunc='sum')\n",
    "\n",
    "# Print metrics before specified date\n",
    "print(pivot5[pivot5.index < '2023-11-01'].describe())\n",
    "# Print metrics after specified date\n",
    "print(pivot5[pivot5.index >= '2024-01-01'].describe())\n",
    "\n",
    "# 2024 Spending total\n",
    "print(\"\\n2024 Spending Total:\")\n",
    "sumSpendingTotal2024 = pivot5[pivot5.index >= '2024-01-01']['amount'].sum()\n",
    "print(sumSpendingTotal2024)\n",
    "\n",
    "# Pivot 3 is required for looking at specific categories\n",
    "print('\\n\\n')\n",
    "# Print metrics for Grocery spend before specified date\n",
    "print(pivot3[pivot3.index <= '2024-12-30']['Groceries'].describe())\n",
    "print('\\n')\n",
    "# Print metrics for Grocery spend after specified date\n",
    "print(pivot3[pivot3.index >= '2024-01-01']['Groceries'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e1d1f-d7a9-498c-8d3c-0ccc8e04a9e8",
   "metadata": {},
   "source": [
    "### Example: Print all transactions from specified category between specified dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e9c21-c90a-41ce-8aa6-4925a7cf312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all transactions from category \"Mortgage\" between 2024-01-01 and 2024-12-31\n",
    "print(\"Total Mortgage spending\")\n",
    "sumMortgage2024 = abs(dfc[(dfc.categoryName == 'Mortgage') & (dfc.Date > '2024-01-01') & (dfc.Date < '2024-12-31') & (dfc.hideFromReports == False)]['amount'].sum())\n",
    "print(sumMortgage2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23c56e-c17f-4356-9e50-2e26af235725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all transactions from category \"Travel & Vacation\" between 2024-01-01 and 2024-03-01\n",
    "print(\"Total Property Tax spending\")\n",
    "sumPropertyTax2024 = abs(dfc[(dfc.categoryName == 'Taxes') & (dfc.Date > '2024-01-01') & (dfc.Date < '2024-12-31') & (dfc.hideFromReports == False) & (dfc.merchantName.str.contains(\"Pty Tax Online Web|eDeposit\", regex=True))]['amount'].sum())\n",
    "print(sumPropertyTax2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f38f33-f9ce-4edf-b87e-e63590444006",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2024 Spending Total:\")\n",
    "print(sumSpendingTotal2024)\n",
    "print(\"2024 Housing Total:\")\n",
    "print(sumMortgage2024 + sumPropertyTax2024)\n",
    "print(\"2024 Non-Housing Total:\")\n",
    "print(sumSpendingTotal2024 - (sumMortgage2024 + sumPropertyTax2024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef06090-b6de-459f-9d8a-c8740f6aa6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all transactions from category \"Travel & Vacation\" between 2024-01-01 and 2024-03-01\n",
    "dfc[(dfc.categoryName == 'Travel & Vacation') & (dfc.Date > '2024-01-01') & (dfc.Date < '2024-03-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3142790-df93-49fb-a870-cbce18f34068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Costco spend over the past membership year\n",
    "dfc_tmp = dfc[(dfc.merchantName.str.contains('costco|Costco|COSTCO', regex=True) ) & (dfc.Date > '2023-08-01') & (dfc.Date < '2024-08-01')]\n",
    "dfc_tmp = dfc_tmp[~dfc_tmp.plaidName.str.contains('gas|Gas|GAS', regex=True)]\n",
    "print(dfc_tmp.amount.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22febb7-d9a8-4953-b2b3-a150c7003ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Whole Foods spend over the past year\n",
    "dfc_tmp = dfc[(dfc.merchantName.str.contains('whole|Whole|WHOLE', regex=True) ) & (dfc.Date > '2024-01-01') & (dfc.Date < '2024-12-31')]\n",
    "dfc_tmp = dfc_tmp[(dfc_tmp.merchantName.str.contains('foods|Foods|FOODS', regex=True) ) & (dfc_tmp.Date > '2024-01-01') & (dfc_tmp.Date < '2024-12-31')]\n",
    "print(dfc_tmp.amount.sum())\n",
    "print(dfc_tmp.amount.sum()/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df00ec2-72c3-4221-a0ea-e383bd3fa3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Clipper spend\n",
    "dfc_tmp = dfc[(dfc.merchantName.str.contains('clipper|Clipper|CLIPPER', regex=True) ) & (dfc.Date > '2024-01-01') & (dfc.Date < '2024-12-31')]\n",
    "#dfc_tmp = dfc_tmp[~dfc_tmp.plaidName.str.contains('gas|Gas|GAS', regex=True)]\n",
    "print(dfc_tmp.amount.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
